{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AIfyGidjbvYZ"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandrakaku/ml0930/blob/master/DataGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyVmNuFjas5F"
      },
      "source": [
        "from glob import glob\n",
        "from tensorflow.keras import layers, models, optimizers, metrics, losses\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import imgaug.augmenters as iaa\n",
        "import imgaug as ia\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmEzNAiRbWUk"
      },
      "source": [
        "IMG_SIZE = 256 # 生出來影像的大小\n",
        "BATCH_SIZE = 8 # 8個batch size\n",
        "\n",
        "# augmentation\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5), # 水平翻轉(左右互換) (0.5=50%的機率做水平翻轉)\n",
        "    iaa.Flipud(0.5), # 上下顛倒\n",
        "    iaa.Affine(   # 旋轉，平移，縮放\n",
        "        rotate=(-45, 45), # -45度~45度裡隨機轉一個角度\n",
        "        mode=ia.ALL, # edge, reflect, symmetric, warp, constant\n",
        "        shear=(-16,16) # 把圖片壓扁\n",
        "    )\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMIPVGcGNWMv",
        "outputId": "77d20337-0cd2-4635-f16c-68f602e6e7dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "Guo Sandra\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed: invalid oauth code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed: invalid oauth code"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8vn1smZa7K4",
        "outputId": "df4e3cba-4c8b-4157-c9e0-7d13c668ad9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "inputs = layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "x = layers.Conv2D(64, 3, activation='relu')(inputs)\n",
        "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs, x)\n",
        "model.compile(optimizers.Adam(), \n",
        "              loss = losses.categorical_crossentropy)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 254, 254, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 252, 252, 64)      36928     \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 38,980\n",
            "Trainable params: 38,980\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGamraQRbPCL",
        "outputId": "4c510943-7b30-4458-c614-22a3c9d518b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# Read image path\n",
        "img_paths = glob('drive/My Drive/class/勞動部/week8/seed/*/*.png')\n",
        "img_paths[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/My Drive/class/勞動部/week8/seed/Cleavers/33c1f167f.png',\n",
              " 'drive/My Drive/class/勞動部/week8/seed/Cleavers/a07efb1e0.png',\n",
              " 'drive/My Drive/class/勞動部/week8/seed/Cleavers/9b35827fa.png',\n",
              " 'drive/My Drive/class/勞動部/week8/seed/Cleavers/3d9ea1649.png',\n",
              " 'drive/My Drive/class/勞動部/week8/seed/Cleavers/c7b4ce2e3.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U_5Y7zQbfeW"
      },
      "source": [
        "train_img_paths, val_img_paths = train_test_split(img_paths, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT6cVqJXbtuG",
        "outputId": "298c7e2b-a8e6-431e-ec52-1c1407d5447b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_img_paths), len(val_img_paths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1098, 275)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIfyGidjbvYZ"
      },
      "source": [
        "### Data Generator 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLsbxOxzbyUE"
      },
      "source": [
        "# Data Generator\n",
        "def data_generator(data_paths, batch_size, aug=True):\n",
        "    class_map = {'Charlock':0, 'Cleavers': 1, 'Fat Hen': 2, 'Maize': 3}\n",
        "    '''data generator for fit_generator'''\n",
        "    n = len(data_paths)\n",
        "    i = 0\n",
        "    data_paths = data_paths\n",
        "    while True:\n",
        "        image_data = []\n",
        "        class_data = []\n",
        "        for b in range(batch_size):\n",
        "            if i==0:\n",
        "                np.random.shuffle(data_paths)\n",
        "            path = data_paths[i]\n",
        "            img = cv2.imread(path)[:,:,::-1]\n",
        "            # img aug\n",
        "            if aug:\n",
        "                img = seq.augment_image(img)\n",
        "            \n",
        "            # img preprocess\n",
        "            img_resize = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "            img_resize = img_resize/255\n",
        "            \n",
        "            # read label\n",
        "            cls = path.split('/')[-2]\n",
        "\n",
        "            image_data.append(img_resize)\n",
        "            class_data.append(class_map[cls])\n",
        "            i = (i+1) % n # 記錄讀到第幾個\n",
        "        image_data = np.array(image_data)\n",
        "        class_data = np.array(class_data)\n",
        "        class_data = tf.keras.utils.to_categorical(class_data, num_classes = 4)\n",
        "        yield image_data, class_data # while版的return 但是不會再進入迴圈\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJHOVx47cI5-"
      },
      "source": [
        "data_gen_train = data_generator(train_img_paths, batch_size=BATCH_SIZE, aug=True)\n",
        "data_gen_val = data_generator(val_img_paths, batch_size=BATCH_SIZE, aug=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSfPJgnJcUIw"
      },
      "source": [
        "model.fit(data_gen_train, \n",
        "          epochs=1, # 要有60個step = 1 epoch\n",
        "          steps_per_epoch=len(train_img_paths)//BATCH_SIZE, #所有的資料數量/一個batch\n",
        "          validation_data = data_gen_val,\n",
        "          validation_steps = len(val_img_paths) // BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9VxZoHHei58"
      },
      "source": [
        "### Data Generator 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QViQngEZcw5c"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "class DataGenerator(Sequence):\n",
        "    \"\"\"\n",
        "    Generates data for Keras\n",
        "    ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 paths,\n",
        "                 batch_size,\n",
        "                 img_size,\n",
        "                 augment,\n",
        "                 shuffle=True):\n",
        "        self.paths = paths\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.paths))\n",
        "        self.class_map = {'Charlock':0, 'Cleavers': 1, 'Fat Hen': 2, 'Maize': 3}\n",
        "        self.num_classes = len(self.class_map)\n",
        "        self.img_size = img_size\n",
        "        self.augment = augment\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'number of batches per epoch'\n",
        "        return int(np.ceil(len(self.paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "\n",
        "        # Generate indexes of the batch\n",
        "        idxs = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        batch_paths = [self.paths[i] for i in idxs]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(batch_paths)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, paths):\n",
        "        \"\"\"\n",
        "        Generates data containing batch_size samples\n",
        "        \"\"\"\n",
        "        X = np.empty((len(paths), self.img_size, self.img_size, 3), dtype=np.float32)\n",
        "        y = np.empty((len(paths)))\n",
        "\n",
        "        for i, path in enumerate(paths):\n",
        "            img = cv2.imread(path)[:,:,::-1]\n",
        "            # img aug\n",
        "            if self.augment:\n",
        "                img = seq.augment_image(img)\n",
        "            # img preprocess\n",
        "            img = cv2.resize(img, (self.img_size, self.img_size))\n",
        "            img = img / 255.\n",
        "            # read label\n",
        "            cls = path.split('/')[-2]\n",
        "            cls = self.class_map[cls]\n",
        "\n",
        "            X[i] = img\n",
        "            y[i] =  cls\n",
        "        # one-hot encoding\n",
        "        y = tf.keras.utils.to_categorical(y, num_classes=self.num_classes)\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im8Sj2btduA7"
      },
      "source": [
        "data_gen_train = DataGenerator(train_img_paths, batch_size=BATCH_SIZE, img_size=IMG_SIZE, augment=True)\n",
        "data_gen_val = DataGenerator(val_img_paths, batch_size=BATCH_SIZE, img_size=IMG_SIZE, augment=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipAK9aCQfTSA"
      },
      "source": [
        "model.fit(data_gen_train, \n",
        "          epochs=1, \n",
        "          validation_data = data_gen_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDC05tDufWzp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}