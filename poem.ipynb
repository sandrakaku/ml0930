{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poem.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPEs2hytNDKk3j8ajO2T4zx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandrakaku/ml0930/blob/master/poem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot7Ipoi7UJdo"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "url = \"https://github.com/Elwing-Chou/ml0716/raw/master/poem_train.csv\"\n",
        "urlretrieve(url, \"train.csv\")\n",
        "url = \"https://github.com/Elwing-Chou/ml0716/raw/master/poem_test.csv\"\n",
        "urlretrieve(url, \"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOMPo8uIUeui"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\", encoding=\"utf-8\")\n",
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N3fqKxHVSQe"
      },
      "source": [
        "test_df = pd.read_csv(\"test.csv\", encoding=\"utf-8\")\n",
        "test_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq-ehwYKouHZ"
      },
      "source": [
        "# Series.replace({\"李白\":0}) (字典)\n",
        "# unique/value_counts\n",
        "writers = train_df[\"作者\"].unique()\n",
        "trans = {w:i for i, w in enumerate(writers)} #準備好w辭典 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。\n",
        "trans_r = {i:w for i, w in enumerate(writers)} #準備好i辭典\n",
        "y_train = train_df[\"作者\"].replace(trans)\n",
        "y_test = test_df[\"作者\"].replace(trans)\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i4e_DA9renf"
      },
      "source": [
        "# 標點符號, \\n\\r 也要去掉\n",
        "import jieba\n",
        "p = train_df[\"內容\"][0] #這是Series (DataFrame比較漂亮) type(train_df[\"內容\"]) #有標點符號\\n\\r\n",
        "\" \".join(jieba.cut(p))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhI05etzs1Q9"
      },
      "source": [
        "# apply(函式名字)\n",
        "def poemcut(p):\n",
        "  return \" \".join(jieba.cut(p))\n",
        "x_train = train_df[\"內容\"].apply(poemcut)\n",
        "x_test = test_df[\"內容\"].apply(poemcut) #apply很重要喔\n",
        "x_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJajttoTxYDK"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vec = CountVectorizer()\n",
        "x_train_count = vec.fit_transform(x_train)\n",
        "x_test_count = vec.transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkaEwFr7xxEe"
      },
      "source": [
        "x_train_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-O-mCv4yOk2"
      },
      "source": [
        "print(x_train_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkIX9W0-ybT9"
      },
      "source": [
        "# vec.vocabulary_\n",
        "# vec.vocabulary_[\"\\n\"] #確認這些自有沒有在裡面 出errow才是對的\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpUOPWli6Ii7"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB(alpha=0.1)\n",
        "clf.fit(x_train_count, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i4wB-876VI3"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "pre = clf.predict(x_test_count)\n",
        "accuracy_score(pre, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TowLUHf7IFs"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(y_test, pre)\n",
        "pd.DataFrame(mat,\n",
        "      index=[name + \"(原本)\" for name in writers],\n",
        "      columns=[name + \"(預測)\" for name in writers] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqc1_A7r74ne"
      },
      "source": [
        "p = input(\"輸入一首詩:\") # 第一步:分詞\n",
        "x_predict = vec.transfrom([poemcut(p)])\n",
        "clf.predict_proba(x_predict)\n",
        "for w, p in zip(writers, proba):\n",
        "  print(w, \":\", p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MjcrJng9IKg"
      },
      "source": [
        "# list(zip([0, 2, 3], [4, 5, 6])) # 你給出的所有list裡對應相同的位置的值合併"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}